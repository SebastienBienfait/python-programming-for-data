{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/futureCodersSE/python-programming-for-data/blob/main/Worksheets/12_WatsonToneAnalyser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyS2Fb7jTftO"
      },
      "source": [
        "# Mini-project - creating a dataframe from analysed text data\n",
        "\n",
        "For this project you are going to use the IBM Watson Tone Analyser API.  You will send text data to it, use security information stored in a config file to keep it secret, receive the results in JSON format, investigate the structure of the results and build a dataframe from them.\n",
        "\n",
        "Then you will use the results to create a visualisation of tone and to report an overall set of statistics from the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsZ4_b2rTftU"
      },
      "source": [
        "---\n",
        "\n",
        "## Step 1 - sign up for IBM Watson services to use the Tone Analyser\n",
        "\n",
        "1.  Sign up for IBM Watson: https://www.ibm.com/cloud/watson-studio  \n",
        "2.  Click 'Try on Cloud at no cost'  \n",
        "3.  Select the London region  (costs reduced and performance improved when you use the nearest servers)  \n",
        "4.  Create an IBM Cloud account (enter email and accept terms)  \n",
        "5.  Follow the instructions to create the account  \n",
        "6.  Provision the services  \n",
        "7.  Then go to IBM Watson Studio  \n",
        "8.  Select Tone Analyzer under the Your Services heading  \n",
        "9.  You will be shown the **url** for the Tone Analyser API and an **API key** which is needed for using the API."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 - add security to your worksheet to keep your apikey and url hidden\n",
        "\n",
        "You can do this by using environment variables, which are stored in the operating system for this worksheet.\n",
        "\n",
        "We will use a simplified system for storing the sensitive data so that it isn't visible in the worksheet:\n",
        "\n",
        "1.  Ask for the api key to be input and store it in an environment variable called apikey\n",
        "\n",
        "2.  Ask for the url to be input and store it in an environment variable\n",
        "\n",
        "3.  Run the cell, type in the api key, then the url.  Once tis has been done.  Remove the output part of the cell."
      ],
      "metadata": {
        "id": "ZV19Vcgp2JHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# add the code to ask for the URL, then run this cell and when it has completed, remove the output (note: you will need to do this again if you return to the worksheet)\n",
        "os.environ['APIKEY'] = input(\"Enter API key: \")\n"
      ],
      "metadata": {
        "id": "ZM4PRCOZ2zyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tqs2PZBXTftW"
      },
      "source": [
        "---\n",
        "\n",
        "## Test to make sure it works\n",
        "\n",
        "1.  Open this file, which has some text for you to test with: https://drive.google.com/file/d/1m65cPQGYQd1mwvEmfZw69-GMUBdo43k0/view?usp=sharing.  You will be able to copy and paste the text into here as needed.\n",
        "\n",
        "2.  Get the environment variable for each of the two pieces of security information so that these do not need to be included in your notebook (have the keys available for copying and pasting).  To do this:\n",
        "\n",
        "  ``` apikey = os.environ.get('APIKEY') ```\n",
        "\n",
        "3.  Run the code below,which will create a ToneAnalyzer with the credentials from your environment variables, then paste the text from the **text-for-analysis.txt** file\n",
        "\n",
        "4.  Decide what the data looks like and how this might be represented in a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f_zyVYfTftY"
      },
      "outputs": [],
      "source": [
        "from ibm_watson import ToneAnalyzerV3\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "import os\n",
        "import json\n",
        "\n",
        "# get credentials from the environment variables you set\n",
        "def get_secret(key):\n",
        "    # add code here to get the keys from the environment variable and return the values as a tuple (apikey, url)\n",
        "    # if there is an error print an error message and return None\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "def get_text_for_analysis():\n",
        "    # add code here to input the text from the text-for-analysis.txt file and return the text it reads as one string\n",
        "    # if there is an error, return None\n",
        "\n",
        "\n",
        "     \n",
        "    \n",
        "# create a ToneAnalyzerV3 object, version 2017-09-21 using api key and url from config\n",
        "authenticator = IAMAuthenticator(apikey=get_secret('apikey'))\n",
        "tone_analyzer = ToneAnalyzerV3(\n",
        "    version='2017-09-21',\n",
        "    authenticator=authenticator\n",
        ")\n",
        "tone_analyzer.set_service_url(get_secret('url'))\n",
        "\n",
        "# get the text for analysis from the file\n",
        "text = get_text_for_analysis()\n",
        "if text:\n",
        "    tone_analysis = tone_analyzer.tone(\n",
        "        {'text': text},\n",
        "        content_type='application/json'\n",
        "    ).get_result()    \n",
        "    print(tone_analysis)\n",
        "else:\n",
        "    print(\"No data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMHlV6wpTftb"
      },
      "source": [
        "### Create (on paper) an idea of how this data might be organised into a data table\n",
        "\n",
        "1.  How many bits of information are there about the document as a whole?\n",
        "2.  How many bits of information are there about each sentence?\n",
        "3.  If all tone analysis records were included in the dataframe, how many rows would there be?\n",
        "4.  What information would be included in each row?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ-p60NeTftc"
      },
      "source": [
        "### Create a dataframe and start to populate with the data\n",
        "\n",
        "Before you can create a dataframe from this data you will need to convert it into a table.  One way to do this would be to create a list of dictionary records, with each record formed from the data from each row in the original 'sentences_tone' data.  You will need to loop through the rows in the 'sentences_tone' list, nesting a loop through the 'tones' list for each sentence.  For each, copy across the columns you feel should be included.\n",
        "\n",
        "_Hint:_  \n",
        "` for row in sentence_data:\n",
        "        for col in row['tones']:\n",
        "            new_row = {'sentence_id':row['sentence_id'], 'text':row['text'], 'tone_score':col['score'], 'tone_id':col['tone_id'],'tone_name':col['tone_name']}`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thFgfS13Tftc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# convert json data to table format with one row for each tone for each sentence\n",
        "def convert_to_tones_table(json_data):\n",
        "    # add code here to convert the json_data from the text file into a table form\n",
        "    # return the data normalized into a dataframe (pd.json_normalise(json_table))\n",
        "\n",
        "\n",
        "\n",
        "tone_data = convert_to_tones_table(tone_analysis)\n",
        "tone_data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LBNPm67Tfte"
      },
      "source": [
        "### Summarise the sentence data\n",
        "*  Which sentence is the most analytical?\n",
        "*  which sentence is the least analytical?\n",
        "*  what is the average analytical tone score for the sentences?\n",
        "*  what do the analytical scores look like in a bar chart?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9QNeA6gTftf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5QvI5ilTftf"
      },
      "source": [
        "### Report the tone data for the whole document\n",
        "---\n",
        "\n",
        "Play with the data, create a dataframe for the document_tone, tones data (pd.json_normalize(document_tone\n",
        "Display the document score for each of the tones in the analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "ZY8_msgUTftg"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0KZ9z-QTfth"
      },
      "source": [
        "### Change the text in the text file and analyse the new text.\n",
        "---\n",
        "\n",
        "Here is some alternative, happier text.  Replace the text in the text-for-analysis.txt file with the text below.  Then run the notebook cells again to see the results.\n",
        "\n",
        "But I feel peaceful. Your success in the ring this morning was, to a small degree, my success. Your future is assured. You will live, secure and safe, Wilbur. Nothing can harm you now. These autumn days will shorten and grow cold. The leaves will shake loose from the trees and fall. Christmas will come, and the snows of winter. You will live to enjoy the beauty of the frozen world, for you mean a great deal to Zuckerman and he will not harm you, ever. Winter will pass, the days will lengthen, the ice will melt in the pasture pond. The song sparrow will return and sing, the frogs will awake, the warm wind will blow again. All these sights and sounds and smells will be yours to enjoy, Wilbur-this lovely world, these precious days.\n",
        "\n",
        "### Find your own examples of text, replace the text in the file again, and analyse the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uqp84n5Tfti"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNEs-fNhTfti"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "12. WatsonToneAnalyser.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}